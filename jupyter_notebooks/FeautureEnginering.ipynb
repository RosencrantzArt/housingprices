{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af45cc96",
   "metadata": {},
   "source": [
    "# Feature Enginering Notebook\n",
    "\n",
    "## Objectives  \n",
    "In this notebook, we will explore the collected data to identify and understand the relationships between various house attributes and the sale price. This process will help to identify key features that will be used in the model for predicting house prices. The exploration phase will guide us in selecting the most relevant features and identifying any potential issues with the data (such as missing values or outliers) that may need to be addressed during data preprocessing.\n",
    "\n",
    "## Inputs  \n",
    "- `inputs/datasets/cleaned/TrainSet.csv`  \n",
    "- `inputs/datasets/cleaned/TestSet.csv`  \n",
    "\n",
    "## Outputs  \n",
    "- Identified features correlated with house sale prices  \n",
    "- Visualized relationships between features and the target variable (sale price)  \n",
    "- Insights on the most relevant features to predict sale prices  \n",
    "\n",
    "## Conclusions  \n",
    "During this exploration phase, we will:  \n",
    "- Perform correlation analysis to find the most influential features related to house sale price.  \n",
    "- Visualize these relationships to better understand how each feature contributes to the price.  \n",
    "- Identify and handle potential data issues (e.g., missing values or outliers) that could affect the model's performance.  \n",
    "- Prepare the data for the next steps in feature engineering and model training.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefcc392",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb72350c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.dirname(current_dir))\n",
    "print(\"You set a new current directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf22bd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfeb8fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_set_path = \"outputs/datasets/cleaned/TrainSetCleaned.csv\"\n",
    "TrainSet = pd.read_csv(train_set_path)\n",
    "TrainSet.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594a7edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_path = 'outputs/datasets/cleaned/TestSetCleaned.csv'\n",
    "TestSet = pd.read_csv(test_set_path)\n",
    "TestSet.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75929f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "TrainSetCleaned = pd.read_csv('outputs/datasets/cleaned/TrainSetCleaned.csv')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b698d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ydata_profiling import ProfileReport\n",
    "pandas_report = ProfileReport(df=TrainSetCleaned, minimal=True)\n",
    "pandas_report.to_notebook_iframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8748997d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from feature_engine import transformation as vt\n",
    "from feature_engine.outliers import Winsorizer\n",
    "from feature_engine.encoding import OrdinalEncoder\n",
    "sns.set(style=\"whitegrid\")\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "def FeatureEngineeringAnalysis(df, analysis_type=None):\n",
    "    \"\"\"\n",
    "    - used for quick feature engineering on numerical and categorical variables\n",
    "    to decide which transformation can better transform the distribution shape\n",
    "    - Once transformed, use a reporting tool, like ydata-profiling, to evaluate distributions\n",
    "    \"\"\"\n",
    "    check_missing_values(df)\n",
    "    allowed_types = ['numerical', 'ordinal_encoder', 'outlier_winsorizer']\n",
    "    check_user_entry_on_analysis_type(analysis_type, allowed_types)\n",
    "    list_column_transformers = define_list_column_transformers(analysis_type)\n",
    "\n",
    "    df_feat_eng = pd.DataFrame([])\n",
    "    for column in df.columns:\n",
    "    \n",
    "        df_feat_eng = pd.concat([df_feat_eng, df[column]], axis=1)\n",
    "        for method in list_column_transformers:\n",
    "            df_feat_eng[f\"{column}_{method}\"] = df[column]\n",
    "\n",
    "        df_feat_eng, list_applied_transformers = apply_transformers(\n",
    "            analysis_type, df_feat_eng, column)\n",
    "\n",
    "        transformer_evaluation(\n",
    "            column, list_applied_transformers, analysis_type, df_feat_eng)\n",
    "\n",
    "    return df_feat_eng\n",
    "\n",
    "\n",
    "def check_user_entry_on_analysis_type(analysis_type, allowed_types):\n",
    "    \"\"\" Check analysis type \"\"\"\n",
    "    if analysis_type is None:\n",
    "        raise SystemExit(\n",
    "            f\"You should pass analysis_type parameter as one of the following options: {allowed_types}\")\n",
    "    if analysis_type not in allowed_types:\n",
    "        raise SystemExit(\n",
    "            f\"analysis_type argument should be one of these options: {allowed_types}\")\n",
    "\n",
    "\n",
    "def check_missing_values(df):\n",
    "    if df.isna().sum().sum() != 0:\n",
    "        raise SystemExit(\n",
    "            f\"There is a missing value in your dataset. Please handle that before getting into feature engineering.\")\n",
    "\n",
    "\n",
    "def define_list_column_transformers(analysis_type):\n",
    "    \"\"\" Set suffix columns according to analysis_type\"\"\"\n",
    "    if analysis_type == 'numerical':\n",
    "        list_column_transformers = [\n",
    "            \"log_e\", \"log_10\", \"reciprocal\", \"power\", \"box_cox\", \"yeo_johnson\"]\n",
    "\n",
    "    elif analysis_type == 'ordinal_encoder':\n",
    "        list_column_transformers = [\"ordinal_encoder\"]\n",
    "\n",
    "    elif analysis_type == 'outlier_winsorizer':\n",
    "        list_column_transformers = ['iqr']\n",
    "\n",
    "    return list_column_transformers\n",
    "\n",
    "\n",
    "def apply_transformers(analysis_type, df_feat_eng, column):\n",
    "    for col in df_feat_eng.select_dtypes(include='category').columns:\n",
    "        df_feat_eng[col] = df_feat_eng[col].astype('object')\n",
    "\n",
    "    if analysis_type == 'numerical':\n",
    "        df_feat_eng, list_applied_transformers = FeatEngineering_Numerical(\n",
    "            df_feat_eng, column)\n",
    "\n",
    "    elif analysis_type == 'outlier_winsorizer':\n",
    "        df_feat_eng, list_applied_transformers = FeatEngineering_OutlierWinsorizer(\n",
    "            df_feat_eng, column)\n",
    "\n",
    "    elif analysis_type == 'ordinal_encoder':\n",
    "        df_feat_eng, list_applied_transformers = FeatEngineering_CategoricalEncoder(\n",
    "            df_feat_eng, column)\n",
    "\n",
    "    return df_feat_eng, list_applied_transformers\n",
    "\n",
    "\n",
    "def transformer_evaluation(column, list_applied_transformers, analysis_type, df_feat_eng):\n",
    "    print(f\"* Variable Analyzed: {column}\")\n",
    "    print(f\"* Applied transformation: {list_applied_transformers} \\n\")\n",
    "    for col in [column] + list_applied_transformers:\n",
    "\n",
    "        if analysis_type != 'ordinal_encoder':\n",
    "            DiagnosticPlots_Numerical(df_feat_eng, col)\n",
    "\n",
    "        else:\n",
    "            if col == column:\n",
    "                DiagnosticPlots_Categories(df_feat_eng, col)\n",
    "            else:\n",
    "                DiagnosticPlots_Numerical(df_feat_eng, col)\n",
    "\n",
    "        print(\"\\n\")\n",
    "\n",
    "\n",
    "def DiagnosticPlots_Categories(df_feat_eng, col):\n",
    "    plt.figure(figsize=(4, 3))\n",
    "    sns.countplot(data=df_feat_eng, x=col, palette=[\n",
    "                  '#432371'], order=df_feat_eng[col].value_counts().index)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.suptitle(f\"{col}\", fontsize=30, y=1.05)\n",
    "    plt.show()\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "def DiagnosticPlots_Numerical(df, variable):\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "    sns.histplot(data=df, x=variable, kde=True, element=\"step\", ax=axes[0])\n",
    "    stats.probplot(df[variable], dist=\"norm\", plot=axes[1])\n",
    "    sns.boxplot(x=df[variable], ax=axes[2])\n",
    "\n",
    "    axes[0].set_title('Histogram')\n",
    "    axes[1].set_title('QQ Plot')\n",
    "    axes[2].set_title('Boxplot')\n",
    "    fig.suptitle(f\"{variable}\", fontsize=30, y=1.05)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def FeatEngineering_CategoricalEncoder(df_feat_eng, column):\n",
    "    list_methods_worked = []\n",
    "    try:\n",
    "        encoder = OrdinalEncoder(encoding_method='arbitrary', variables=[\n",
    "                                 f\"{column}_ordinal_encoder\"])\n",
    "        df_feat_eng = encoder.fit_transform(df_feat_eng)\n",
    "        list_methods_worked.append(f\"{column}_ordinal_encoder\")\n",
    "\n",
    "    except Exception:\n",
    "        df_feat_eng.drop([f\"{column}_ordinal_encoder\"], axis=1, inplace=True)\n",
    "\n",
    "    return df_feat_eng, list_methods_worked\n",
    "\n",
    "\n",
    "def FeatEngineering_OutlierWinsorizer(df_feat_eng, column):\n",
    "    list_methods_worked = []\n",
    "\n",
    "    try:\n",
    "        disc = Winsorizer(\n",
    "            capping_method='iqr', tail='both', fold=1.5, variables=[f\"{column}_iqr\"])\n",
    "        df_feat_eng = disc.fit_transform(df_feat_eng)\n",
    "        list_methods_worked.append(f\"{column}_iqr\")\n",
    "    except Exception:\n",
    "        df_feat_eng.drop([f\"{column}_iqr\"], axis=1, inplace=True)\n",
    "\n",
    "    return df_feat_eng, list_methods_worked\n",
    "\n",
    "\n",
    "def FeatEngineering_Numerical(df_feat_eng, column):\n",
    "    list_methods_worked = []\n",
    "\n",
    "    try:\n",
    "        lt = vt.LogTransformer(variables=[f\"{column}_log_e\"])\n",
    "        df_feat_eng = lt.fit_transform(df_feat_eng)\n",
    "        list_methods_worked.append(f\"{column}_log_e\")\n",
    "    except Exception:\n",
    "        df_feat_eng.drop([f\"{column}_log_e\"], axis=1, inplace=True)\n",
    "\n",
    "    try:\n",
    "        lt = vt.LogTransformer(variables=[f\"{column}_log_10\"], base='10')\n",
    "        df_feat_eng = lt.fit_transform(df_feat_eng)\n",
    "        list_methods_worked.append(f\"{column}_log_10\")\n",
    "    except Exception:\n",
    "        df_feat_eng.drop([f\"{column}_log_10\"], axis=1, inplace=True)\n",
    "\n",
    "    try:\n",
    "        rt = vt.ReciprocalTransformer(variables=[f\"{column}_reciprocal\"])\n",
    "        df_feat_eng = rt.fit_transform(df_feat_eng)\n",
    "        list_methods_worked.append(f\"{column}_reciprocal\")\n",
    "    except Exception:\n",
    "        df_feat_eng.drop([f\"{column}_reciprocal\"], axis=1, inplace=True)\n",
    "\n",
    "    try:\n",
    "        pt = vt.PowerTransformer(variables=[f\"{column}_power\"])\n",
    "        df_feat_eng = pt.fit_transform(df_feat_eng)\n",
    "        list_methods_worked.append(f\"{column}_power\")\n",
    "    except Exception:\n",
    "        df_feat_eng.drop([f\"{column}_power\"], axis=1, inplace=True)\n",
    "\n",
    "    try:\n",
    "        bct = vt.BoxCoxTransformer(variables=[f\"{column}_box_cox\"])\n",
    "        df_feat_eng = bct.fit_transform(df_feat_eng)\n",
    "        list_methods_worked.append(f\"{column}_box_cox\")\n",
    "    except Exception:\n",
    "        df_feat_eng.drop([f\"{column}_box_cox\"], axis=1, inplace=True)\n",
    "\n",
    "    try:\n",
    "        yjt = vt.YeoJohnsonTransformer(variables=[f\"{column}_yeo_johnson\"])\n",
    "        df_feat_eng = yjt.fit_transform(df_feat_eng)\n",
    "        list_methods_worked.append(f\"{column}_yeo_johnson\")\n",
    "    except Exception:\n",
    "        df_feat_eng.drop([f\"{column}_yeo_johnson\"], axis=1, inplace=True)\n",
    "\n",
    "    return df_feat_eng, list_methods_worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76452a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_engineering= [\n",
    "    '1stFlrSF', '2ndFlrSF', 'BedroomAbvGr', 'BsmtExposure', 'BsmtFinSF1',\n",
    "    'BsmtFinType1', 'BsmtUnfSF', 'GarageArea', 'GarageFinish', 'GarageYrBlt',\n",
    "    'GrLivArea', 'KitchenQual', 'LotArea', 'LotFrontage', 'MasVnrArea',\n",
    "    'OpenPorchSF', 'OverallCond', 'OverallQual', 'TotalBsmtSF',\n",
    "    'YearBuilt', 'YearRemodAdd'\n",
    "]\n",
    "\n",
    "variables_engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c02e2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = pd.read_csv('outputs/datasets/cleaned/TestSetCleaned.csv')\n",
    "\n",
    "df_engineering = testset[variables_engineering].copy()\n",
    "\n",
    "df_engineering.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e8ad89",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_engineering = TrainSet[variables_engineering].copy()\n",
    "df_engineering.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba1f42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "variables_engineering = [\n",
    "    '1stFlrSF', '2ndFlrSF', 'GrLivArea', 'LotArea', 'MasVnrArea',\n",
    "    'OpenPorchSF', 'OverallCond', 'OverallQual', 'TotalBsmtSF',\n",
    "    'YearBuilt', 'YearRemodAdd'\n",
    "]\n",
    "\n",
    "df_engineering = TrainSet[variables_engineering].copy()\n",
    "df_engineering.head(3)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df_engineering_scaled = scaler.fit_transform(df_engineering)\n",
    "\n",
    "print(df_engineering_scaled[:3])\n",
    "\n",
    "TrainSet[variables_engineering] = scaler.fit_transform(TrainSet[variables_engineering])\n",
    "TestSet[variables_engineering] = scaler.transform(TestSet[variables_engineering])\n",
    "\n",
    "print(\"* Numerical transformation - scaling done!\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20061821",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from feature_engine.selection import SmartCorrelatedSelection\n",
    "\n",
    "variables_engineering = [\n",
    "    '1stFlrSF', '2ndFlrSF', 'GrLivArea', 'LotArea', 'MasVnrArea',\n",
    "    'OpenPorchSF', 'OverallCond', 'OverallQual', 'TotalBsmtSF',\n",
    "    'YearBuilt', 'YearRemodAdd'\n",
    "]\n",
    "\n",
    "df_engineering = TrainSet[variables_engineering].copy()\n",
    "\n",
    "df_engineering.head(3)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df_engineering_scaled = scaler.fit_transform(df_engineering)\n",
    "\n",
    "print(df_engineering_scaled[:3])\n",
    "\n",
    "TrainSet[variables_engineering] = scaler.fit_transform(TrainSet[variables_engineering])\n",
    "TestSet[variables_engineering] = scaler.transform(TestSet[variables_engineering])\n",
    "\n",
    "print(\"* Numerical transformation - scaling done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc7ceb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_engineering = TrainSet.copy()\n",
    "\n",
    "from feature_engine.selection import SmartCorrelatedSelection\n",
    "\n",
    "corr_sel = SmartCorrelatedSelection(\n",
    "    variables=None, \n",
    "    method=\"spearman\", \n",
    "    threshold=0.6, \n",
    "    selection_method=\"variance\" \n",
    ")\n",
    "\n",
    "corr_sel.fit_transform(df_engineering)\n",
    "\n",
    "print(\"Correlated feature sets:\", corr_sel.correlated_feature_sets_)\n",
    "\n",
    "print(\"Features to drop:\", corr_sel.features_to_drop_)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.12.1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
